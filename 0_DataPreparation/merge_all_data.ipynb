{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier werden alle Daten aus verschiedenen Quellen zu einem großen Dataframe zusammen gefasst. Das sind zum einen die Daten welche uns vom Kurs zu Verfügung gestellt wurden, als auch die daten welche wir selber noch gefunden haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#packete für data handling laden\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum  Bewoelkung  Temperatur  Windgeschwindigkeit  Wettercode\n",
      "0  2012-01-01         8.0      9.8250                   14        58.0\n",
      "1  2012-01-02         7.0      7.4375                   12         NaN\n",
      "2  2012-01-03         8.0      5.5375                   18        63.0\n",
      "3  2012-01-04         4.0      5.6875                   19        80.0\n",
      "4  2012-01-05         6.0      5.3000                   23        80.0\n",
      "           Datum  Bewoelkung  Temperatur  Windgeschwindigkeit  Wettercode\n",
      "2596  2019-07-28         3.0     23.3500                   14         5.0\n",
      "2597  2019-07-29         6.0     25.2500                    7        61.0\n",
      "2598  2019-07-30         7.0     20.7375                    8        61.0\n",
      "2599  2019-07-31         6.0     20.4500                    7        61.0\n",
      "2600  2019-08-01         5.0     21.0625                    9        61.0\n",
      "(2601, 5)\n",
      "        Datum  Warengruppe      Umsatz\n",
      "0  2013-07-01            1  148.828353\n",
      "1  2013-07-02            1  159.793757\n",
      "2  2013-07-03            1  111.885594\n",
      "3  2013-07-04            1  168.864941\n",
      "4  2013-07-05            1  171.280754\n",
      "           Datum  Warengruppe     Umsatz\n",
      "9329  2017-12-21            6  87.471228\n",
      "9330  2017-12-22            6  71.911652\n",
      "9331  2017-12-23            6  84.062223\n",
      "9332  2017-12-24            6  60.981969\n",
      "9333  2017-12-27            6  34.972644\n",
      "(9334, 3)\n",
      "        Datum  KielerWoche\n",
      "0  2012-06-16            1\n",
      "1  2012-06-17            1\n",
      "2  2012-06-18            1\n",
      "3  2012-06-19            1\n",
      "4  2012-06-20            1\n",
      "         Datum  KielerWoche\n",
      "67  2019-06-26            1\n",
      "68  2019-06-27            1\n",
      "69  2019-06-28            1\n",
      "70  2019-06-29            1\n",
      "71  2019-06-30            1\n",
      "(72, 2)\n"
     ]
    }
   ],
   "source": [
    "#Einlesen der Basisidaten, welche wir zur verfügung gestellt bekommen haben\n",
    "#Wetterdaten\n",
    "wetter = pd.read_csv(\"../wetter.csv\")\n",
    "print(wetter.head())\n",
    "print(wetter.tail())\n",
    "print(wetter.shape)\n",
    "\n",
    "#Umsatzdaten\n",
    "umsatz = pd.read_csv(\"../umsatzdaten_gekuerzt.csv\")\n",
    "print(umsatz.head())\n",
    "print(umsatz.tail())\n",
    "print(umsatz.shape)\n",
    "\n",
    "#Kieler Woche Daten\n",
    "kiwo = pd.read_csv(\"../kiwo.csv\")\n",
    "print(kiwo.head())\n",
    "print(kiwo.tail())\n",
    "print(kiwo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Umsatzdaten sind im long format nach Warengruppen. Bedeutet, dass jedes Datum mehrmals vorkommt. Das ist zum mergen der Daten nicht ideal. Daher den dataframe vom long format ins wide format bringen. \n",
    "In diesem Zuge werden direkt auch die Warengruppen richtig benannt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum        Brot   Broetchen   Crossaint  Konditorei      Kuchen  \\\n",
      "0  2013-07-01  148.828353  535.856285  201.198426   65.890169  317.475875   \n",
      "1  2013-07-02  159.793757  546.780787  265.261254   74.543917  383.628682   \n",
      "2  2013-07-03  111.885594  427.343259  210.260241   69.262728  305.523072   \n",
      "3  2013-07-04  168.864941  454.859641  190.686641   61.490175  308.408168   \n",
      "4  2013-07-05  171.280754  492.818804  181.644870   86.759861  355.518770   \n",
      "\n",
      "   Saisonbrot  \n",
      "0         NaN  \n",
      "1         NaN  \n",
      "2         NaN  \n",
      "3         NaN  \n",
      "4         NaN  \n",
      "           Datum        Brot   Broetchen   Crossaint  Konditorei      Kuchen  \\\n",
      "1814  2018-07-27  198.225523  677.415844  333.774099   65.563734  297.867853   \n",
      "1815  2018-07-28  214.470393  716.576825  371.819770   54.047422  290.024007   \n",
      "1816  2018-07-29  129.801991  721.822447  433.820697  128.952852  335.823557   \n",
      "1817  2018-07-30  148.541340  616.358562  348.770346   71.822977  324.965348   \n",
      "1818  2018-07-31  123.075682  586.081666  285.872616   57.102795  261.341313   \n",
      "\n",
      "      Saisonbrot  \n",
      "1814         NaN  \n",
      "1815         NaN  \n",
      "1816         NaN  \n",
      "1817         NaN  \n",
      "1818         NaN  \n",
      "(1819, 7)\n"
     ]
    }
   ],
   "source": [
    "#get the umsart data in the wide format\n",
    "# Pivot the DataFrame\n",
    "umsatz_shaped = umsatz.pivot(index='Datum', columns='Warengruppe', values='Umsatz')\n",
    "\n",
    "# Reset the index to make 'date' a column again\n",
    "umsatz_shaped.reset_index(inplace=True)\n",
    "\n",
    "#get colums names right\n",
    "umsatz_shaped.columns = ['Datum', 'Brot', 'Broetchen', 'Crossaint', 'Konditorei', 'Kuchen', 'Saisonbrot']\n",
    "\n",
    "print(umsatz_shaped.head())\n",
    "print(umsatz_shaped.tail())    \n",
    "print(umsatz_shaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum        Brot   Broetchen   Crossaint  Konditorei      Kuchen  \\\n",
      "0  2013-07-01  148.828353  535.856285  201.198426   65.890169  317.475875   \n",
      "1  2013-07-02  159.793757  546.780787  265.261254   74.543917  383.628682   \n",
      "2  2013-07-03  111.885594  427.343259  210.260241   69.262728  305.523072   \n",
      "3  2013-07-04  168.864941  454.859641  190.686641   61.490175  308.408168   \n",
      "4  2013-07-05  171.280754  492.818804  181.644870   86.759861  355.518770   \n",
      "\n",
      "   Saisonbrot  Umsatz_total  \n",
      "0         0.0          1269  \n",
      "1         0.0          1430  \n",
      "2         0.0          1124  \n",
      "3         0.0          1184  \n",
      "4         0.0          1288  \n",
      "(1819, 8)\n"
     ]
    }
   ],
   "source": [
    "#aufräumen der Daten. NaN durch 0 ersetzen\n",
    "umsatz_shaped.fillna(0, inplace=True)\n",
    "\n",
    "#Eine Spalte hinzufügen in welcher der Gesamtumsatz steht\n",
    "umsatz_shaped['Umsatz_total'] = umsatz_shaped['Brot'] + umsatz_shaped['Broetchen'] + umsatz_shaped['Crossaint'] + umsatz_shaped['Konditorei'] + umsatz_shaped['Kuchen'] + umsatz_shaped['Saisonbrot']\n",
    "umsatz_shaped['Umsatz_total'] = umsatz_shaped['Umsatz_total'].astype(int)\n",
    "print(umsatz_shaped.head())\n",
    "print(umsatz_shaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum        Brot   Broetchen   Crossaint  Konditorei      Kuchen  \\\n",
      "0  2013-07-01  148.828353  535.856285  201.198426   65.890169  317.475875   \n",
      "1  2013-07-02  159.793757  546.780787  265.261254   74.543917  383.628682   \n",
      "2  2013-07-03  111.885594  427.343259  210.260241   69.262728  305.523072   \n",
      "3  2013-07-04  168.864941  454.859641  190.686641   61.490175  308.408168   \n",
      "4  2013-07-05  171.280754  492.818804  181.644870   86.759861  355.518770   \n",
      "\n",
      "   Saisonbrot  Umsatz_total  Bewoelkung  Temperatur  Windgeschwindigkeit  \\\n",
      "0         0.0          1269         6.0     17.8375                 15.0   \n",
      "1         0.0          1430         3.0     17.3125                 10.0   \n",
      "2         0.0          1124         7.0     21.0750                  6.0   \n",
      "3         0.0          1184         7.0     18.8500                  7.0   \n",
      "4         0.0          1288         5.0     19.9750                 12.0   \n",
      "\n",
      "   Wettercode  \n",
      "0        20.0  \n",
      "1         NaN  \n",
      "2        61.0  \n",
      "3        20.0  \n",
      "4         NaN  \n",
      "(1819, 12)\n"
     ]
    }
   ],
   "source": [
    "#nun können die Umsatzdaten mit den Wetterdaten zusammengeführt werden\n",
    "#merge the data\n",
    "data = pd.merge(umsatz_shaped,wetter, how='left', on='Datum')\n",
    "print(data.head())\n",
    "print(data.shape)\n",
    "\n",
    "#es werden nun die Zeilen behalten, für welche es Umsatzdaten gibt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum        Brot   Broetchen   Crossaint  Konditorei      Kuchen  \\\n",
      "0  2013-07-01  148.828353  535.856285  201.198426   65.890169  317.475875   \n",
      "1  2013-07-02  159.793757  546.780787  265.261254   74.543917  383.628682   \n",
      "2  2013-07-03  111.885594  427.343259  210.260241   69.262728  305.523072   \n",
      "3  2013-07-04  168.864941  454.859641  190.686641   61.490175  308.408168   \n",
      "4  2013-07-05  171.280754  492.818804  181.644870   86.759861  355.518770   \n",
      "\n",
      "   Saisonbrot  Umsatz_total  Bewoelkung  Temperatur  Windgeschwindigkeit  \\\n",
      "0         0.0          1269         6.0     17.8375                 15.0   \n",
      "1         0.0          1430         3.0     17.3125                 10.0   \n",
      "2         0.0          1124         7.0     21.0750                  6.0   \n",
      "3         0.0          1184         7.0     18.8500                  7.0   \n",
      "4         0.0          1288         5.0     19.9750                 12.0   \n",
      "\n",
      "   Wettercode  KielerWoche  \n",
      "0        20.0          NaN  \n",
      "1         NaN          NaN  \n",
      "2        61.0          NaN  \n",
      "3        20.0          NaN  \n",
      "4         NaN          NaN  \n",
      "(1819, 13)\n",
      "        Datum        Brot   Broetchen   Crossaint  Konditorei      Kuchen  \\\n",
      "0  2013-07-01  148.828353  535.856285  201.198426   65.890169  317.475875   \n",
      "1  2013-07-02  159.793757  546.780787  265.261254   74.543917  383.628682   \n",
      "2  2013-07-03  111.885594  427.343259  210.260241   69.262728  305.523072   \n",
      "3  2013-07-04  168.864941  454.859641  190.686641   61.490175  308.408168   \n",
      "4  2013-07-05  171.280754  492.818804  181.644870   86.759861  355.518770   \n",
      "\n",
      "   Saisonbrot  Umsatz_total  Bewoelkung  Temperatur  Windgeschwindigkeit  \\\n",
      "0         0.0          1269         6.0     17.8375                 15.0   \n",
      "1         0.0          1430         3.0     17.3125                 10.0   \n",
      "2         0.0          1124         7.0     21.0750                  6.0   \n",
      "3         0.0          1184         7.0     18.8500                  7.0   \n",
      "4         0.0          1288         5.0     19.9750                 12.0   \n",
      "\n",
      "   Wettercode  KielerWoche  \n",
      "0        20.0            0  \n",
      "1         NaN            0  \n",
      "2        61.0            0  \n",
      "3        20.0            0  \n",
      "4         NaN            0  \n"
     ]
    }
   ],
   "source": [
    "# und nun noch die Kieler Woche Daten hinzufügen\n",
    "data = pd.merge(data, kiwo, how='left', on='Datum')\n",
    "print(data.head())\n",
    "print(data.shape)\n",
    "\n",
    "#im moment steht da eine 1.0 wenn es Kieler Woche ist und eine NaN wenn nicht. Das ändern wir jetzt\n",
    "data['KielerWoche'] = data['KielerWoche'].fillna(0)\n",
    "data['KielerWoche'] = data['KielerWoche'].astype(int)\n",
    "print(data.head())\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun haben wir alle Basisidaten zusammen geführt. Jetzt können noch die Variablen, welche wir selber gesucht haben hinzugefügt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum   VPI\n",
      "0  2013-07-01  98.9\n",
      "1  2013-07-02  98.9\n",
      "2  2013-07-03  98.9\n",
      "3  2013-07-04  98.9\n",
      "4  2013-07-05  98.9\n",
      "           Datum    VPI\n",
      "1852  2018-07-27  104.4\n",
      "1853  2018-07-28  104.4\n",
      "1854  2018-07-29  104.4\n",
      "1855  2018-07-30  104.4\n",
      "1856  2018-07-31  104.4\n",
      "(1857, 2)\n"
     ]
    }
   ],
   "source": [
    "#hinzufügen der Inflationsdaten\n",
    "#einlesen der Daten\n",
    "inflation = pd.read_csv(\"./02_Verbraucherpreisindex/vpi_daily.csv\")\n",
    "print(inflation.head())\n",
    "print(inflation.tail())\n",
    "print(inflation.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum        Brot   Broetchen   Crossaint  Konditorei      Kuchen  \\\n",
      "0  2013-07-01  148.828353  535.856285  201.198426   65.890169  317.475875   \n",
      "1  2013-07-02  159.793757  546.780787  265.261254   74.543917  383.628682   \n",
      "2  2013-07-03  111.885594  427.343259  210.260241   69.262728  305.523072   \n",
      "3  2013-07-04  168.864941  454.859641  190.686641   61.490175  308.408168   \n",
      "4  2013-07-05  171.280754  492.818804  181.644870   86.759861  355.518770   \n",
      "\n",
      "   Saisonbrot  Umsatz_total  Bewoelkung  Temperatur  Windgeschwindigkeit  \\\n",
      "0         0.0          1269         6.0     17.8375                 15.0   \n",
      "1         0.0          1430         3.0     17.3125                 10.0   \n",
      "2         0.0          1124         7.0     21.0750                  6.0   \n",
      "3         0.0          1184         7.0     18.8500                  7.0   \n",
      "4         0.0          1288         5.0     19.9750                 12.0   \n",
      "\n",
      "   Wettercode  KielerWoche   VPI  \n",
      "0        20.0            0  98.9  \n",
      "1         NaN            0  98.9  \n",
      "2        61.0            0  98.9  \n",
      "3        20.0            0  98.9  \n",
      "4         NaN            0  98.9  \n",
      "(1819, 14)\n"
     ]
    }
   ],
   "source": [
    "#mergen der Daten\n",
    "data = pd.merge(data, inflation, how='left', on='Datum')    \n",
    "print(data.head())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Weekday Arrival_date Departure_date      Ship       Pier\n",
      "0      So     31.03.12       31.03.12  AIDAcara  Ostseekai\n",
      "1      So     07.04.12       07.04.12  AIDAcara  Ostseekai\n",
      "2      So     14.04.12       14.04.12  AIDAcara  Ostseekai\n",
      "3      So     21.04.12       21.04.12  AIDAcara  Ostseekai\n",
      "4      So     28.04.12       28.04.12  AIDAcara  Ostseekai\n",
      "  Arrival_date Departure_date      Ship\n",
      "0     31.03.12       31.03.12  AIDAcara\n",
      "1     07.04.12       07.04.12  AIDAcara\n",
      "2     14.04.12       14.04.12  AIDAcara\n",
      "3     21.04.12       21.04.12  AIDAcara\n",
      "4     28.04.12       28.04.12  AIDAcara\n",
      "  Arrival_date Departure_date      Ship\n",
      "0   2012-03-31       31.03.12  AIDAcara\n",
      "1   2012-07-04       07.04.12  AIDAcara\n",
      "2   2012-04-14       14.04.12  AIDAcara\n",
      "3   2012-04-21       21.04.12  AIDAcara\n",
      "4   2012-04-28       28.04.12  AIDAcara\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4586/1555327337.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  schiffe['Arrival_date'] = pd.to_datetime(schiffe['Arrival_date'])\n"
     ]
    }
   ],
   "source": [
    "#hinzufügen der Kreuzfahrschfissdaten\n",
    "schiffe = pd.read_csv(\"./01_Kreuzfahrtschiffe/kiel_all.csv\")\n",
    "print(schiffe.head())\n",
    "\n",
    "#create a subset of the data\n",
    "schiffe = schiffe[['Arrival_date', 'Departure_date','Ship']]\n",
    "print(schiffe.head())\n",
    "\n",
    "#format arrival and departure date\n",
    "schiffe['Arrival_date'] = pd.to_datetime(schiffe['Arrival_date'])\n",
    "#converte the date to a string for merging\n",
    "schiffe['Arrival_date'] = schiffe['Arrival_date'].dt.strftime('%Y-%m-%d')\n",
    "#schiffe['Departure_date'] = pd.to_datetime(schiffe['Departure_date'], format='%Y-%m-%d')\n",
    "print(schiffe.head())\n",
    "\n",
    "print(type(data['Datum'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum        Brot   Broetchen   Crossaint  Konditorei      Kuchen  \\\n",
      "0  2013-07-01  148.828353  535.856285  201.198426   65.890169  317.475875   \n",
      "1  2013-07-02  159.793757  546.780787  265.261254   74.543917  383.628682   \n",
      "2  2013-07-03  111.885594  427.343259  210.260241   69.262728  305.523072   \n",
      "3  2013-07-04  168.864941  454.859641  190.686641   61.490175  308.408168   \n",
      "4  2013-07-05  171.280754  492.818804  181.644870   86.759861  355.518770   \n",
      "\n",
      "   Saisonbrot  Umsatz_total  Bewoelkung  Temperatur  Windgeschwindigkeit  \\\n",
      "0         0.0          1269         6.0     17.8375                 15.0   \n",
      "1         0.0          1430         3.0     17.3125                 10.0   \n",
      "2         0.0          1124         7.0     21.0750                  6.0   \n",
      "3         0.0          1184         7.0     18.8500                  7.0   \n",
      "4         0.0          1288         5.0     19.9750                 12.0   \n",
      "\n",
      "   Wettercode  KielerWoche   VPI Arrival_date Departure_date        Ship  \\\n",
      "0        20.0            0  98.9          NaN            NaN         NaN   \n",
      "1         NaN            0  98.9          NaN            NaN         NaN   \n",
      "2        61.0            0  98.9          NaN            NaN         NaN   \n",
      "3        20.0            0  98.9          NaN            NaN         NaN   \n",
      "4         NaN            0  98.9   2013-07-05       07.05.13  MSC Poesia   \n",
      "\n",
      "      _merge  \n",
      "0  left_only  \n",
      "1  left_only  \n",
      "2  left_only  \n",
      "3  left_only  \n",
      "4       both  \n",
      "(1952, 18)\n"
     ]
    }
   ],
   "source": [
    "#merge the data\n",
    "data = pd.merge(data, schiffe, how='left', left_on='Datum', right_on='Arrival_date', indicator=True)\n",
    "print(data.head())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'MSC Poesia'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Achtung an manchen Tagen kommen mehrere Schiffe an. Das müssen wir noch bereinigen\t\u001b[39;00m\n\u001b[1;32m      2\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShip\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShip\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShip\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mShip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m/workspaces/bakery_sales_prediction/.venv/lib/python3.12/site-packages/pandas/core/generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   6639\u001b[0m     ]\n\u001b[1;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/workspaces/bakery_sales_prediction/.venv/lib/python3.12/site-packages/pandas/core/internals/managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/bakery_sales_prediction/.venv/lib/python3.12/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m/workspaces/bakery_sales_prediction/.venv/lib/python3.12/site-packages/pandas/core/internals/blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/bakery_sales_prediction/.venv/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/workspaces/bakery_sales_prediction/.venv/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/workspaces/bakery_sales_prediction/.venv/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'MSC Poesia'"
     ]
    }
   ],
   "source": [
    "#Achtung an manchen Tagen kommen mehrere Schiffe an. Das müssen wir noch bereinigen\t\n",
    "data['Ship'] = data['Ship'].fillna(0)\n",
    "data['Ship'] = data['Ship'].astype(int)\n",
    "print(data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
