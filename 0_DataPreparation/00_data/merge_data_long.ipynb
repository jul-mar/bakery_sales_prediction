{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier werden alle Daten aus verschiedenen Quellen zu einem großen Dataframe zusammen gefasst. Das sind zum einen die Daten welche uns vom Kurs zu Verfügung gestellt wurden, als auch die daten welche wir selber noch gefunden haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#packete für data handling laden\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum  Warengruppe      Umsatz\n",
      "0  2013-07-01            1  148.828353\n",
      "1  2013-07-02            1  159.793757\n",
      "2  2013-07-03            1  111.885594\n",
      "3  2013-07-04            1  168.864941\n",
      "4  2013-07-05            1  171.280754\n",
      "           Datum  Warengruppe     Umsatz\n",
      "9329  2017-12-21            6  87.471228\n",
      "9330  2017-12-22            6  71.911652\n",
      "9331  2017-12-23            6  84.062223\n",
      "9332  2017-12-24            6  60.981969\n",
      "9333  2017-12-27            6  34.972644\n",
      "(9334, 3)\n"
     ]
    }
   ],
   "source": [
    "#Einlesen der Basisidaten, welche wir zur verfügung gestellt bekommen haben\n",
    "\n",
    "#Umsatzdaten\n",
    "umsatz = pd.read_csv(\"/workspaces/bakery_sales_prediction/0_DataPreparation/umsatzdaten_gekuerzt.csv\")\n",
    "print(umsatz.head())\n",
    "print(umsatz.tail())\n",
    "print(umsatz.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum      Umsatz  Warengruppe_1  Warengruppe_2  Warengruppe_3  \\\n",
      "0  2013-07-01  148.828353              1              0              0   \n",
      "1  2013-07-02  159.793757              1              0              0   \n",
      "2  2013-07-03  111.885594              1              0              0   \n",
      "3  2013-07-04  168.864941              1              0              0   \n",
      "4  2013-07-05  171.280754              1              0              0   \n",
      "\n",
      "   Warengruppe_4  Warengruppe_5  Warengruppe_6  \n",
      "0              0              0              0  \n",
      "1              0              0              0  \n",
      "2              0              0              0  \n",
      "3              0              0              0  \n",
      "4              0              0              0  \n"
     ]
    }
   ],
   "source": [
    "#Warengruppen one hot encoden\n",
    "\n",
    "umsatz = pd.get_dummies(umsatz, columns=['Warengruppe'])\n",
    "umsatz = umsatz * 1\n",
    "print(umsatz.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum  Temp_Very_Cold  Temp_Cold  Temp_Mild  Temp_Warm  Temp_Hot  \\\n",
      "0  2012-01-01               0          1          0          0         0   \n",
      "1  2012-01-02               0          1          0          0         0   \n",
      "2  2012-01-03               0          1          0          0         0   \n",
      "3  2012-01-04               0          1          0          0         0   \n",
      "4  2012-01-05               0          1          0          0         0   \n",
      "\n",
      "   Cloud_Clear  Cloud_Partly_Cloudy  Cloud_Cloudy  Wind_Light  Wind_Moderate  \\\n",
      "0            0                    0             1           0              1   \n",
      "1            0                    0             1           0              1   \n",
      "2            0                    0             1           0              0   \n",
      "3            0                    1             0           0              0   \n",
      "4            0                    0             1           0              0   \n",
      "\n",
      "   Wind_Strong  Weather_Good  Weather_Light_Issues  Weather_Moderate  \\\n",
      "0            0             0                     1                 0   \n",
      "1            0             0                     1                 0   \n",
      "2            1             0                     1                 0   \n",
      "3            1             0                     0                 0   \n",
      "4            1             0                     0                 0   \n",
      "\n",
      "   Weather_Severe  \n",
      "0               0  \n",
      "1               0  \n",
      "2               0  \n",
      "3               1  \n",
      "4               1  \n",
      "           Datum  Temp_Very_Cold  Temp_Cold  Temp_Mild  Temp_Warm  Temp_Hot  \\\n",
      "2765  2019-07-28               0          0          0          1         0   \n",
      "2766  2019-07-29               0          0          0          0         1   \n",
      "2767  2019-07-30               0          0          0          1         0   \n",
      "2768  2019-07-31               0          0          0          1         0   \n",
      "2769  2019-08-01               0          0          0          1         0   \n",
      "\n",
      "      Cloud_Clear  Cloud_Partly_Cloudy  Cloud_Cloudy  Wind_Light  \\\n",
      "2765            0                    1             0           0   \n",
      "2766            0                    0             1           1   \n",
      "2767            0                    0             1           1   \n",
      "2768            0                    0             1           1   \n",
      "2769            0                    1             0           0   \n",
      "\n",
      "      Wind_Moderate  Wind_Strong  Weather_Good  Weather_Light_Issues  \\\n",
      "2765              1            0             0                     0   \n",
      "2766              0            0             0                     1   \n",
      "2767              0            0             0                     1   \n",
      "2768              0            0             0                     1   \n",
      "2769              1            0             0                     1   \n",
      "\n",
      "      Weather_Moderate  Weather_Severe  \n",
      "2765                 1               0  \n",
      "2766                 0               0  \n",
      "2767                 0               0  \n",
      "2768                 0               0  \n",
      "2769                 0               0  \n",
      "(2770, 16)\n"
     ]
    }
   ],
   "source": [
    "#Wetterdaten\n",
    "wetter = pd.read_csv(\"/workspaces/bakery_sales_prediction/0_DataPreparation/07_Wetter/07_wetter.csv\")\n",
    "print(wetter.head())\n",
    "print(wetter.tail())\n",
    "print(wetter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum  KielerWoche\n",
      "0  2012-06-16            1\n",
      "1  2012-06-17            1\n",
      "2  2012-06-18            1\n",
      "3  2012-06-19            1\n",
      "4  2012-06-20            1\n",
      "         Datum  KielerWoche\n",
      "67  2019-06-26            1\n",
      "68  2019-06-27            1\n",
      "69  2019-06-28            1\n",
      "70  2019-06-29            1\n",
      "71  2019-06-30            1\n",
      "(72, 2)\n"
     ]
    }
   ],
   "source": [
    "#Kieler Woche Daten\n",
    "kiwo = pd.read_csv(\"/workspaces/bakery_sales_prediction/0_DataPreparation/kiwo.csv\")\n",
    "print(kiwo.head())\n",
    "print(kiwo.tail())\n",
    "print(kiwo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum      Umsatz  Warengruppe_1  Warengruppe_2  Warengruppe_3  \\\n",
      "0  2013-07-01  148.828353              1              0              0   \n",
      "1  2013-07-02  159.793757              1              0              0   \n",
      "2  2013-07-03  111.885594              1              0              0   \n",
      "3  2013-07-04  168.864941              1              0              0   \n",
      "4  2013-07-05  171.280754              1              0              0   \n",
      "\n",
      "   Warengruppe_4  Warengruppe_5  Warengruppe_6  Temp_Very_Cold  Temp_Cold  \\\n",
      "0              0              0              0               0          0   \n",
      "1              0              0              0               0          0   \n",
      "2              0              0              0               0          0   \n",
      "3              0              0              0               0          0   \n",
      "4              0              0              0               0          0   \n",
      "\n",
      "   ...  Cloud_Clear  Cloud_Partly_Cloudy  Cloud_Cloudy  Wind_Light  \\\n",
      "0  ...            0                    0             1           0   \n",
      "1  ...            0                    1             0           0   \n",
      "2  ...            0                    0             1           1   \n",
      "3  ...            0                    0             1           1   \n",
      "4  ...            0                    1             0           0   \n",
      "\n",
      "   Wind_Moderate  Wind_Strong  Weather_Good  Weather_Light_Issues  \\\n",
      "0              1            0             0                     1   \n",
      "1              1            0             0                     1   \n",
      "2              0            0             0                     1   \n",
      "3              0            0             0                     1   \n",
      "4              1            0             0                     1   \n",
      "\n",
      "   Weather_Moderate  Weather_Severe  \n",
      "0                 0               0  \n",
      "1                 0               0  \n",
      "2                 0               0  \n",
      "3                 0               0  \n",
      "4                 0               0  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "(9334, 23)\n"
     ]
    }
   ],
   "source": [
    "#nun können die Umsatzdaten mit den Wetterdaten zusammengeführt werden\n",
    "#merge the data\n",
    "data = pd.merge(umsatz,wetter, how='left', on='Datum')\n",
    "print(data.head())\n",
    "print(data.shape)\n",
    "\n",
    "#es werden nur die Zeilen behalten, für welche es Umsatzdaten gibt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum      Umsatz  Warengruppe_1  Warengruppe_2  Warengruppe_3  \\\n",
      "0  2013-07-01  148.828353              1              0              0   \n",
      "1  2013-07-02  159.793757              1              0              0   \n",
      "2  2013-07-03  111.885594              1              0              0   \n",
      "3  2013-07-04  168.864941              1              0              0   \n",
      "4  2013-07-05  171.280754              1              0              0   \n",
      "\n",
      "   Warengruppe_4  Warengruppe_5  Warengruppe_6  Temp_Very_Cold  Temp_Cold  \\\n",
      "0              0              0              0               0          0   \n",
      "1              0              0              0               0          0   \n",
      "2              0              0              0               0          0   \n",
      "3              0              0              0               0          0   \n",
      "4              0              0              0               0          0   \n",
      "\n",
      "   ...  Cloud_Partly_Cloudy  Cloud_Cloudy  Wind_Light  Wind_Moderate  \\\n",
      "0  ...                    0             1           0              1   \n",
      "1  ...                    1             0           0              1   \n",
      "2  ...                    0             1           1              0   \n",
      "3  ...                    0             1           1              0   \n",
      "4  ...                    1             0           0              1   \n",
      "\n",
      "   Wind_Strong  Weather_Good  Weather_Light_Issues  Weather_Moderate  \\\n",
      "0            0             0                     1                 0   \n",
      "1            0             0                     1                 0   \n",
      "2            0             0                     1                 0   \n",
      "3            0             0                     1                 0   \n",
      "4            0             0                     1                 0   \n",
      "\n",
      "   Weather_Severe  KielerWoche  \n",
      "0               0          NaN  \n",
      "1               0          NaN  \n",
      "2               0          NaN  \n",
      "3               0          NaN  \n",
      "4               0          NaN  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "(9334, 24)\n",
      "        Datum      Umsatz  Warengruppe_1  Warengruppe_2  Warengruppe_3  \\\n",
      "0  2013-07-01  148.828353              1              0              0   \n",
      "1  2013-07-02  159.793757              1              0              0   \n",
      "2  2013-07-03  111.885594              1              0              0   \n",
      "3  2013-07-04  168.864941              1              0              0   \n",
      "4  2013-07-05  171.280754              1              0              0   \n",
      "\n",
      "   Warengruppe_4  Warengruppe_5  Warengruppe_6  Temp_Very_Cold  Temp_Cold  \\\n",
      "0              0              0              0               0          0   \n",
      "1              0              0              0               0          0   \n",
      "2              0              0              0               0          0   \n",
      "3              0              0              0               0          0   \n",
      "4              0              0              0               0          0   \n",
      "\n",
      "   ...  Cloud_Partly_Cloudy  Cloud_Cloudy  Wind_Light  Wind_Moderate  \\\n",
      "0  ...                    0             1           0              1   \n",
      "1  ...                    1             0           0              1   \n",
      "2  ...                    0             1           1              0   \n",
      "3  ...                    0             1           1              0   \n",
      "4  ...                    1             0           0              1   \n",
      "\n",
      "   Wind_Strong  Weather_Good  Weather_Light_Issues  Weather_Moderate  \\\n",
      "0            0             0                     1                 0   \n",
      "1            0             0                     1                 0   \n",
      "2            0             0                     1                 0   \n",
      "3            0             0                     1                 0   \n",
      "4            0             0                     1                 0   \n",
      "\n",
      "   Weather_Severe  KielerWoche  \n",
      "0               0            0  \n",
      "1               0            0  \n",
      "2               0            0  \n",
      "3               0            0  \n",
      "4               0            0  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "(9334, 24)\n"
     ]
    }
   ],
   "source": [
    "# und nun noch die Kieler Woche Daten hinzufügen\n",
    "data = pd.merge(data, kiwo, how='left', on='Datum')\n",
    "print(data.head())\n",
    "print(data.shape)\n",
    "\n",
    "#im moment steht da eine 1.0 wenn es Kieler Woche ist und eine NaN wenn nicht. Das ändern wir jetzt\n",
    "data['KielerWoche'] = data['KielerWoche'].fillna(0)\n",
    "data['KielerWoche'] = data['KielerWoche'].astype(int)\n",
    "print(data.head())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum  Montag  Dienstag  Mittwoch  Donnerstag  Freitag  Samstag  \\\n",
      "0  2013-07-01       1         0         0           0        0        0   \n",
      "1  2013-07-02       0         1         0           0        0        0   \n",
      "2  2013-07-03       0         0         1           0        0        0   \n",
      "3  2013-07-04       0         0         0           1        0        0   \n",
      "4  2013-07-05       0         0         0           0        1        0   \n",
      "\n",
      "   Sonntag  \n",
      "0        0  \n",
      "1        0  \n",
      "2        0  \n",
      "3        0  \n",
      "4        0  \n",
      "        Datum      Umsatz  Warengruppe_1  Warengruppe_2  Warengruppe_3  \\\n",
      "0  2013-07-01  148.828353              1              0              0   \n",
      "1  2013-07-02  159.793757              1              0              0   \n",
      "2  2013-07-03  111.885594              1              0              0   \n",
      "3  2013-07-04  168.864941              1              0              0   \n",
      "4  2013-07-05  171.280754              1              0              0   \n",
      "\n",
      "   Warengruppe_4  Warengruppe_5  Warengruppe_6  Temp_Very_Cold  Temp_Cold  \\\n",
      "0              0              0              0               0          0   \n",
      "1              0              0              0               0          0   \n",
      "2              0              0              0               0          0   \n",
      "3              0              0              0               0          0   \n",
      "4              0              0              0               0          0   \n",
      "\n",
      "   ...  Weather_Moderate  Weather_Severe  KielerWoche  Montag  Dienstag  \\\n",
      "0  ...                 0               0            0       1         0   \n",
      "1  ...                 0               0            0       0         1   \n",
      "2  ...                 0               0            0       0         0   \n",
      "3  ...                 0               0            0       0         0   \n",
      "4  ...                 0               0            0       0         0   \n",
      "\n",
      "   Mittwoch  Donnerstag  Freitag  Samstag  Sonntag  \n",
      "0         0           0        0        0        0  \n",
      "1         0           0        0        0        0  \n",
      "2         1           0        0        0        0  \n",
      "3         0           1        0        0        0  \n",
      "4         0           0        1        0        0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "(9334, 31)\n"
     ]
    }
   ],
   "source": [
    "#Wochentage hinzugefügen\n",
    "wochentag = pd.read_csv(\"/workspaces/bakery_sales_prediction/0_DataPreparation/09_Wochentage/Wochentage.csv\")\n",
    "print(wochentag.head())\n",
    "\n",
    "#mergen der Daten\n",
    "data = pd.merge(data, wochentag, how='left', on='Datum')\n",
    "print(data.head())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun haben wir alle Basisidaten zusammen geführt. Jetzt können noch die Variablen, welche wir selber gesucht haben hinzugefügt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum   VPI\n",
      "0  2013-07-01  98.9\n",
      "1  2013-07-02  98.9\n",
      "2  2013-07-03  98.9\n",
      "3  2013-07-04  98.9\n",
      "4  2013-07-05  98.9\n",
      "(1857, 2)\n",
      "        Datum      Umsatz  Warengruppe_1  Warengruppe_2  Warengruppe_3  \\\n",
      "0  2013-07-01  148.828353              1              0              0   \n",
      "1  2013-07-02  159.793757              1              0              0   \n",
      "2  2013-07-03  111.885594              1              0              0   \n",
      "3  2013-07-04  168.864941              1              0              0   \n",
      "4  2013-07-05  171.280754              1              0              0   \n",
      "\n",
      "   Warengruppe_4  Warengruppe_5  Warengruppe_6  Temp_Very_Cold  Temp_Cold  \\\n",
      "0              0              0              0               0          0   \n",
      "1              0              0              0               0          0   \n",
      "2              0              0              0               0          0   \n",
      "3              0              0              0               0          0   \n",
      "4              0              0              0               0          0   \n",
      "\n",
      "   ...  Weather_Severe  KielerWoche  Montag  Dienstag  Mittwoch  Donnerstag  \\\n",
      "0  ...               0            0       1         0         0           0   \n",
      "1  ...               0            0       0         1         0           0   \n",
      "2  ...               0            0       0         0         1           0   \n",
      "3  ...               0            0       0         0         0           1   \n",
      "4  ...               0            0       0         0         0           0   \n",
      "\n",
      "   Freitag  Samstag  Sonntag   VPI  \n",
      "0        0        0        0  98.9  \n",
      "1        0        0        0  98.9  \n",
      "2        0        0        0  98.9  \n",
      "3        0        0        0  98.9  \n",
      "4        1        0        0  98.9  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "(9334, 32)\n"
     ]
    }
   ],
   "source": [
    "#hinzufügen der Inflationsdaten\n",
    "#einlesen der Daten\n",
    "inflation = pd.read_csv(\"/workspaces/bakery_sales_prediction/0_DataPreparation/02_Verbraucherpreisindex/vpi_daily.csv\")\n",
    "print(inflation.head())\n",
    "print(inflation.shape)\n",
    "\n",
    "#mergen der Daten\n",
    "data = pd.merge(data, inflation, how='left', on='Datum')    \n",
    "print(data.head())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum  Number_of_ships  Ship\n",
      "0  2013-07-01              0.0     0\n",
      "1  2013-07-02              0.0     0\n",
      "2  2013-07-03              0.0     0\n",
      "3  2013-07-04              0.0     0\n",
      "4  2013-07-05              1.0     1\n"
     ]
    }
   ],
   "source": [
    "#hinzufügen der Kreuzfahrschfissdaten\n",
    "schiffe = pd.read_csv(\"/workspaces/bakery_sales_prediction/0_DataPreparation/01_Kreuzfahrtschiffe/Alle_Schiffe.csv\")\n",
    "print(schiffe.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum      Umsatz  Warengruppe_1  Warengruppe_2  Warengruppe_3  \\\n",
      "0  2013-07-01  148.828353              1              0              0   \n",
      "1  2013-07-02  159.793757              1              0              0   \n",
      "2  2013-07-03  111.885594              1              0              0   \n",
      "3  2013-07-04  168.864941              1              0              0   \n",
      "4  2013-07-05  171.280754              1              0              0   \n",
      "\n",
      "   Warengruppe_4  Warengruppe_5  Warengruppe_6  Temp_Very_Cold  Temp_Cold  \\\n",
      "0              0              0              0               0          0   \n",
      "1              0              0              0               0          0   \n",
      "2              0              0              0               0          0   \n",
      "3              0              0              0               0          0   \n",
      "4              0              0              0               0          0   \n",
      "\n",
      "   ...  Montag  Dienstag  Mittwoch  Donnerstag  Freitag  Samstag  Sonntag  \\\n",
      "0  ...       1         0         0           0        0        0        0   \n",
      "1  ...       0         1         0           0        0        0        0   \n",
      "2  ...       0         0         1           0        0        0        0   \n",
      "3  ...       0         0         0           1        0        0        0   \n",
      "4  ...       0         0         0           0        1        0        0   \n",
      "\n",
      "    VPI  Number_of_ships  Ship  \n",
      "0  98.9              0.0     0  \n",
      "1  98.9              0.0     0  \n",
      "2  98.9              0.0     0  \n",
      "3  98.9              0.0     0  \n",
      "4  98.9              1.0     1  \n",
      "\n",
      "[5 rows x 34 columns]\n",
      "(9334, 34)\n"
     ]
    }
   ],
   "source": [
    "#merge the data\n",
    "data = pd.merge(data, schiffe, how='left', left_on='Datum', right_on='Datum')\n",
    "\n",
    "#fill NaN with False\n",
    "data['Ship'] = data['Ship'].fillna(False)\n",
    "\n",
    "print(data.head())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum  Heimspiel\n",
      "0  2013-01-01          0\n",
      "1  2013-01-02          0\n",
      "2  2013-01-03          0\n",
      "3  2013-01-04          0\n",
      "4  2013-01-05          0\n",
      "(2922, 2)\n"
     ]
    }
   ],
   "source": [
    "#importieren der heimspiel daten\n",
    "heimspiele = pd.read_csv(\"/workspaces/bakery_sales_prediction/0_DataPreparation/03_Heimspiele/Kiel_Heimspiele.csv\", sep=',')\n",
    "\n",
    "print(heimspiele.head())\n",
    "print(heimspiele.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum      Umsatz  Warengruppe_1  Warengruppe_2  Warengruppe_3  \\\n",
      "0  2013-07-01  148.828353              1              0              0   \n",
      "1  2013-07-02  159.793757              1              0              0   \n",
      "2  2013-07-03  111.885594              1              0              0   \n",
      "3  2013-07-04  168.864941              1              0              0   \n",
      "4  2013-07-05  171.280754              1              0              0   \n",
      "\n",
      "   Warengruppe_4  Warengruppe_5  Warengruppe_6  Temp_Very_Cold  Temp_Cold  \\\n",
      "0              0              0              0               0          0   \n",
      "1              0              0              0               0          0   \n",
      "2              0              0              0               0          0   \n",
      "3              0              0              0               0          0   \n",
      "4              0              0              0               0          0   \n",
      "\n",
      "   ...  Dienstag  Mittwoch  Donnerstag  Freitag  Samstag  Sonntag   VPI  \\\n",
      "0  ...         0         0           0        0        0        0  98.9   \n",
      "1  ...         1         0           0        0        0        0  98.9   \n",
      "2  ...         0         1           0        0        0        0  98.9   \n",
      "3  ...         0         0           1        0        0        0  98.9   \n",
      "4  ...         0         0           0        1        0        0  98.9   \n",
      "\n",
      "   Number_of_ships  Ship  Heimspiel  \n",
      "0              0.0     0          0  \n",
      "1              0.0     0          0  \n",
      "2              0.0     0          0  \n",
      "3              0.0     0          0  \n",
      "4              1.0     1          0  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "(9334, 35)\n"
     ]
    }
   ],
   "source": [
    "#mergen der heimspiel Daten\n",
    "data = pd.merge(data, heimspiele, how='left', left_on='Datum', right_on='Datum')\n",
    "print(data.head())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum  Feiertag\n",
      "0  2013-07-01         0\n",
      "1  2013-07-02         0\n",
      "2  2013-07-03         0\n",
      "3  2013-07-04         0\n",
      "4  2013-07-05         0\n",
      "(2375, 2)\n"
     ]
    }
   ],
   "source": [
    "#Feiertagsdaten hochladen\n",
    "feiertage = pd.read_csv(\"/workspaces/bakery_sales_prediction/0_DataPreparation/04_Feiertage/feiertage_final.csv\", sep=';')\n",
    "print(feiertage.head())\n",
    "print(feiertage.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum      Umsatz  Warengruppe_1  Warengruppe_2  Warengruppe_3  \\\n",
      "0  2013-07-01  148.828353              1              0              0   \n",
      "1  2013-07-02  159.793757              1              0              0   \n",
      "2  2013-07-03  111.885594              1              0              0   \n",
      "3  2013-07-04  168.864941              1              0              0   \n",
      "4  2013-07-05  171.280754              1              0              0   \n",
      "\n",
      "   Warengruppe_4  Warengruppe_5  Warengruppe_6  Temp_Very_Cold  Temp_Cold  \\\n",
      "0              0              0              0               0          0   \n",
      "1              0              0              0               0          0   \n",
      "2              0              0              0               0          0   \n",
      "3              0              0              0               0          0   \n",
      "4              0              0              0               0          0   \n",
      "\n",
      "   ...  Mittwoch  Donnerstag  Freitag  Samstag  Sonntag   VPI  \\\n",
      "0  ...         0           0        0        0        0  98.9   \n",
      "1  ...         0           0        0        0        0  98.9   \n",
      "2  ...         1           0        0        0        0  98.9   \n",
      "3  ...         0           1        0        0        0  98.9   \n",
      "4  ...         0           0        1        0        0  98.9   \n",
      "\n",
      "   Number_of_ships  Ship  Heimspiel  Feiertag  \n",
      "0              0.0     0          0         0  \n",
      "1              0.0     0          0         0  \n",
      "2              0.0     0          0         0  \n",
      "3              0.0     0          0         0  \n",
      "4              1.0     1          0         0  \n",
      "\n",
      "[5 rows x 36 columns]\n",
      "(9334, 36)\n"
     ]
    }
   ],
   "source": [
    "#und mergen der feiertagsdaten\n",
    "data = pd.merge(data, feiertage, how='left', left_on='Datum', right_on='Datum')\n",
    "print(data.head())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum  is_holiday\n",
      "0  2013-01-01           0\n",
      "1  2013-01-02           0\n",
      "2  2013-01-03           0\n",
      "3  2013-01-04           0\n",
      "4  2013-01-05           0\n",
      "        Datum      Umsatz  Warengruppe_1  Warengruppe_2  Warengruppe_3  \\\n",
      "0  2013-07-01  148.828353              1              0              0   \n",
      "1  2013-07-02  159.793757              1              0              0   \n",
      "2  2013-07-03  111.885594              1              0              0   \n",
      "3  2013-07-04  168.864941              1              0              0   \n",
      "4  2013-07-05  171.280754              1              0              0   \n",
      "\n",
      "   Warengruppe_4  Warengruppe_5  Warengruppe_6  Temp_Very_Cold  Temp_Cold  \\\n",
      "0              0              0              0               0          0   \n",
      "1              0              0              0               0          0   \n",
      "2              0              0              0               0          0   \n",
      "3              0              0              0               0          0   \n",
      "4              0              0              0               0          0   \n",
      "\n",
      "   ...  Donnerstag  Freitag  Samstag  Sonntag   VPI  Number_of_ships  Ship  \\\n",
      "0  ...           0        0        0        0  98.9              0.0     0   \n",
      "1  ...           0        0        0        0  98.9              0.0     0   \n",
      "2  ...           0        0        0        0  98.9              0.0     0   \n",
      "3  ...           1        0        0        0  98.9              0.0     0   \n",
      "4  ...           0        1        0        0  98.9              1.0     1   \n",
      "\n",
      "   Heimspiel  Feiertag  is_holiday  \n",
      "0          0         0           0  \n",
      "1          0         0           0  \n",
      "2          0         0           0  \n",
      "3          0         0           0  \n",
      "4          0         0           0  \n",
      "\n",
      "[5 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "#hinzufügen der Feriendaten\n",
    "ferien = pd.read_csv(\"/workspaces/bakery_sales_prediction/0_DataPreparation/06_Ferientage/06_ferientage.csv\")\n",
    "print(ferien.head())\n",
    "\n",
    "#und mergen der Feriendaten\n",
    "data = pd.merge(data, ferien, how='left', left_on='Datum', right_on='Datum')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum  Weihnachtsmarkt  Markt\n",
      "0  2013-01-01                0      0\n",
      "1  2013-01-02                0      0\n",
      "2  2013-01-03                0      0\n",
      "3  2013-01-04                0      0\n",
      "4  2013-01-05                0      0\n",
      "        Datum      Umsatz  Warengruppe_1  Warengruppe_2  Warengruppe_3  \\\n",
      "0  2013-07-01  148.828353              1              0              0   \n",
      "1  2013-07-02  159.793757              1              0              0   \n",
      "2  2013-07-03  111.885594              1              0              0   \n",
      "3  2013-07-04  168.864941              1              0              0   \n",
      "4  2013-07-05  171.280754              1              0              0   \n",
      "\n",
      "   Warengruppe_4  Warengruppe_5  Warengruppe_6  Temp_Very_Cold  Temp_Cold  \\\n",
      "0              0              0              0               0          0   \n",
      "1              0              0              0               0          0   \n",
      "2              0              0              0               0          0   \n",
      "3              0              0              0               0          0   \n",
      "4              0              0              0               0          0   \n",
      "\n",
      "   ...  Samstag  Sonntag   VPI  Number_of_ships  Ship  Heimspiel  Feiertag  \\\n",
      "0  ...        0        0  98.9              0.0     0          0         0   \n",
      "1  ...        0        0  98.9              0.0     0          0         0   \n",
      "2  ...        0        0  98.9              0.0     0          0         0   \n",
      "3  ...        0        0  98.9              0.0     0          0         0   \n",
      "4  ...        0        0  98.9              1.0     1          0         0   \n",
      "\n",
      "   is_holiday  Weihnachtsmarkt  Markt  \n",
      "0           0                0      0  \n",
      "1           0                0      0  \n",
      "2           0                0      0  \n",
      "3           0                0      0  \n",
      "4           0                0      0  \n",
      "\n",
      "[5 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "#hinzufügen der Märkte\n",
    "marktdaten = pd.read_csv(\"/workspaces/bakery_sales_prediction/0_DataPreparation/08_Maerkte/maekte_final.csv\")\n",
    "print(marktdaten.head())\n",
    "\n",
    "#und mergen der Marktdaten\n",
    "data = pd.merge(data, marktdaten, how='left', left_on='Datum', right_on='Datum')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damit sind alle Daten gemerged und der df kann als csv zur weiteren Bearbeitung exportiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exportieren der Daten als csv\n",
    "data.to_csv(\"data_long.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7493, 39)\n",
      "(1841, 39)\n"
     ]
    }
   ],
   "source": [
    "#teilern der Daten in einen Trainingsdatensatz und einen Validierungsdatensatz\n",
    "#trinaingsdaten sollen vom 01.07.2013 bis 31.07.20217 gehen\n",
    "#validierungsdaten sollen vom 01.08.2017 bis 31.07.2018 gehen\n",
    "train = data[data['Datum'] < '2017-08-01']\n",
    "valid = data[data['Datum'] >= '2017-08-01']\n",
    "\n",
    "print(train.shape)\n",
    "print(valid.shape)\n",
    "\n",
    "#exportieren der Daten als csv\n",
    "train.to_csv(\"Trainingsdaten_long.csv\", index=False)\n",
    "valid.to_csv(\"Validierungsdaten_long.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Warengruppe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Warengruppe'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#get the umsatz data in the wide format\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Pivot the DataFrame\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m umsatz_shaped \u001b[38;5;241m=\u001b[39m \u001b[43mumsatz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpivot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDatum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWarengruppe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUmsatz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Reset the index to make 'date' a column again\u001b[39;00m\n\u001b[1;32m      6\u001b[0m umsatz_shaped\u001b[38;5;241m.\u001b[39mreset_index(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py:9339\u001b[0m, in \u001b[0;36mDataFrame.pivot\u001b[0;34m(self, columns, index, values)\u001b[0m\n\u001b[1;32m   9332\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   9333\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpivot\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   9334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpivot\u001b[39m(\n\u001b[1;32m   9335\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, columns, index\u001b[38;5;241m=\u001b[39mlib\u001b[38;5;241m.\u001b[39mno_default, values\u001b[38;5;241m=\u001b[39mlib\u001b[38;5;241m.\u001b[39mno_default\n\u001b[1;32m   9336\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   9337\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpivot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pivot\n\u001b[0;32m-> 9339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpivot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/reshape/pivot.py:555\u001b[0m, in \u001b[0;36mpivot\u001b[0;34m(data, columns, index, values)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    553\u001b[0m     index_list \u001b[38;5;241m=\u001b[39m [data[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m com\u001b[38;5;241m.\u001b[39mconvert_to_list_like(index)]\n\u001b[0;32m--> 555\u001b[0m data_columns \u001b[38;5;241m=\u001b[39m [\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns_listlike]\n\u001b[1;32m    556\u001b[0m index_list\u001b[38;5;241m.\u001b[39mextend(data_columns)\n\u001b[1;32m    557\u001b[0m multiindex \u001b[38;5;241m=\u001b[39m MultiIndex\u001b[38;5;241m.\u001b[39mfrom_arrays(index_list)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Warengruppe'"
     ]
    }
   ],
   "source": [
    "\n",
    "#get the umsatz data in the wide format\n",
    "# Pivot the DataFrame\n",
    "umsatz_shaped = umsatz.pivot(index='Datum', columns='Warengruppe', values='Umsatz')\n",
    "\n",
    "# Reset the index to make 'date' a column again\n",
    "umsatz_shaped.reset_index(inplace=True)\n",
    "\n",
    "#get colums names right\n",
    "umsatz_shaped.columns = ['Datum', 'Brot', 'Broetchen', 'Croissant', 'Konditorei', 'Kuchen', 'Saisonbrot']\n",
    "\n",
    "#aufräumen der Daten. NaN durch 0 ersetzen\n",
    "umsatz_shaped.fillna(0, inplace=True)\n",
    "\n",
    "print(umsatz_shaped.head())\n",
    "print(umsatz_shaped.tail())    \n",
    "print(umsatz_shaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum        Brot   Broetchen   Croissant  Konditorei      Kuchen  \\\n",
      "0  2013-07-01  148.828353  535.856285  201.198426   65.890169  317.475875   \n",
      "1  2013-07-02  159.793757  546.780787  265.261254   74.543917  383.628682   \n",
      "2  2013-07-03  111.885594  427.343259  210.260241   69.262728  305.523072   \n",
      "3  2013-07-04  168.864941  454.859641  190.686641   61.490175  308.408168   \n",
      "4  2013-07-05  171.280754  492.818804  181.644870   86.759861  355.518770   \n",
      "\n",
      "   Saisonbrot  Umsatz_total  \n",
      "0         0.0          1269  \n",
      "1         0.0          1430  \n",
      "2         0.0          1124  \n",
      "3         0.0          1184  \n",
      "4         0.0          1288  \n",
      "(1819, 8)\n"
     ]
    }
   ],
   "source": [
    "#Eine Spalte hinzufügen in welcher der Gesamtumsatz steht\n",
    "umsatz_shaped['Umsatz_total'] = umsatz_shaped['Brot'] + umsatz_shaped['Broetchen'] + umsatz_shaped['Croissant'] + umsatz_shaped['Konditorei'] + umsatz_shaped['Kuchen'] + umsatz_shaped['Saisonbrot']\n",
    "umsatz_shaped['Umsatz_total'] = umsatz_shaped['Umsatz_total'].astype(int)\n",
    "\n",
    "\n",
    "print(umsatz_shaped.head())\n",
    "print(umsatz_shaped.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
