{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Training features dimensions: (12103, 34)\n",
      "Loaded Validation features dimensions: (3458, 34)\n",
      "Loaded Test features dimensions: (1729, 34)\n",
      "\n",
      "Loaded Training labels dimensions: (12103, 1)\n",
      "Loaded Validation labels dimensions: (3458, 1)\n",
      "Loaded Test labels dimensions: (1729, 1)\n",
      "\n",
      "First few rows of loaded training features:\n",
      "   bathrooms_0.5  bathrooms_0.75  bathrooms_1.0  bathrooms_1.25  \\\n",
      "0              0               0              1               0   \n",
      "1              0               0              1               0   \n",
      "2              0               0              0               0   \n",
      "3              0               0              0               0   \n",
      "4              0               0              0               0   \n",
      "\n",
      "   bathrooms_1.5  bathrooms_1.75  bathrooms_2.0  bathrooms_2.25  \\\n",
      "0              0               0              0               0   \n",
      "1              0               0              0               0   \n",
      "2              0               0              0               0   \n",
      "3              0               1              0               0   \n",
      "4              0               1              0               0   \n",
      "\n",
      "   bathrooms_2.5  bathrooms_2.75  ...  bathrooms_6.5  bathrooms_6.75  \\\n",
      "0              0               0  ...              0               0   \n",
      "1              0               0  ...              0               0   \n",
      "2              0               0  ...              0               0   \n",
      "3              0               0  ...              0               0   \n",
      "4              0               0  ...              0               0   \n",
      "\n",
      "   bathrooms_7.5  bathrooms_7.75  bathrooms_8.0  condition_2  condition_3  \\\n",
      "0              0               0              0            0            1   \n",
      "1              0               0              0            0            1   \n",
      "2              0               0              0            0            1   \n",
      "3              0               0              0            0            1   \n",
      "4              0               0              0            0            1   \n",
      "\n",
      "   condition_4  condition_5  sqft_living15  \n",
      "0            0            0           1290  \n",
      "1            0            0           1710  \n",
      "2            0            0           3610  \n",
      "3            0            0           1390  \n",
      "4            0            0           1280  \n",
      "\n",
      "[5 rows x 34 columns]\n",
      "\n",
      "First few rows of loaded training labels:\n",
      "       price\n",
      "0   331000.0\n",
      "1   385000.0\n",
      "2   444000.0\n",
      "3   555000.0\n",
      "4  1440000.0\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Define the file paths\n",
    "subdirectory = \"pickle_data_Beispielnotebook\"\n",
    "training_features_path = f\"{subdirectory}/training_features.pkl\"\n",
    "validation_features_path = f\"{subdirectory}/validation_features.pkl\"\n",
    "test_features_path = f\"{subdirectory}/test_features.pkl\"\n",
    "training_labels_path = f\"{subdirectory}/training_labels.pkl\"\n",
    "validation_labels_path = f\"{subdirectory}/validation_labels.pkl\"\n",
    "test_labels_path = f\"{subdirectory}/test_labels.pkl\"\n",
    "\n",
    "# Read the pickle files\n",
    "training_features = pd.read_pickle(training_features_path)\n",
    "validation_features = pd.read_pickle(validation_features_path)\n",
    "test_features = pd.read_pickle(test_features_path)\n",
    "training_labels = pd.read_pickle(training_labels_path)\n",
    "validation_labels = pd.read_pickle(validation_labels_path)\n",
    "test_labels = pd.read_pickle(test_labels_path)\n",
    "\n",
    "# Verify the loaded data by printing their shapes and a few rows\n",
    "print(\"Loaded Training features dimensions:\", training_features.shape)\n",
    "print(\"Loaded Validation features dimensions:\", validation_features.shape)\n",
    "print(\"Loaded Test features dimensions:\", test_features.shape)\n",
    "print()\n",
    "print(\"Loaded Training labels dimensions:\", training_labels.shape)\n",
    "print(\"Loaded Validation labels dimensions:\", validation_labels.shape)\n",
    "print(\"Loaded Test labels dimensions:\", test_labels.shape)\n",
    "print()\n",
    "\n",
    "print(\"First few rows of loaded training features:\")\n",
    "print(training_features.head())\n",
    "print()\n",
    "print(\"First few rows of loaded training labels:\")\n",
    "print(training_labels.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'distutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Defining the Neural Network\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#Now, let's define our neural network. We are using a Sequential model definition from Keras with batch normalization and dense layers.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputLayer, Dense, BatchNormalization\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n",
      "File \u001b[0;32m/workspaces/bakery_sales_prediction/.venv/lib/python3.12/site-packages/tensorflow/__init__.py:30\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03mTop-level module of TensorFlow. By convention, we refer to this module as\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m`tf` instead of `tensorflow`, following the common practice of importing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03mthis file with a file generated from [`api_template.__init__.py`](https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/api_template.__init__.py)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-bad-import-order,protected-access,g-import-not-at-top\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdistutils\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_distutils\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_inspect\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'distutils'"
     ]
    }
   ],
   "source": [
    "#Defining the Neural Network\n",
    "#Now, let's define our neural network. We are using a Sequential model definition from Keras with batch normalization and dense layers.\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential([\n",
    "  InputLayer(shape=(training_features.shape[1], )),\n",
    "  BatchNormalization(),\n",
    "  Dense(10, activation='relu'),\n",
    "  Dense(4, activation='relu'),\n",
    "  Dense(1)\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
