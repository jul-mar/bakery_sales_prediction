{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damit ich ein neuronales Netwerk erstellen kann welches mir Umsatzvorhersagen zu Croissants macht muss ich erst einmal die Daten dafür aufbereiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Import Data \n",
    "#we have split our data already in the trainig data (05-10-2013 - 31-07-2017)\n",
    "data_train = pd.read_csv(\"/workspaces/bakery_sales_prediction/0_DataPreparation/00_data/Trainingsdaten_long.csv\")\n",
    "#the validataion data (01-08-2017 - 31-07-20218)\n",
    "data_val = pd.read_csv(\"/workspaces/bakery_sales_prediction/0_DataPreparation/00_data/Validierungsdaten_long.csv\")\n",
    "#the test data (01-08-2018 - 31-07-2019)\n",
    "data_test = pd.read_csv(\"/workspaces/bakery_sales_prediction/0_DataPreparation/00_data/Testdaten.csv\") \n",
    "\n",
    "#only select the necessary rows for the croissants\n",
    "data_train = data_train[data_train[\"Warengruppe_3\"] == 1]\n",
    "data_val = data_val[data_val[\"Warengruppe_3\"] == 1]\n",
    "data_test = data_test[data_test[\"Warengruppe_3\"] == 1]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Datum      Umsatz  Temp_Very_Cold  Temp_Cold  Temp_Mild  Temp_Warm  \\\n",
      "2924  2013-07-01  201.198426               0          0          1          0   \n",
      "2925  2013-07-02  265.261254               0          0          1          0   \n",
      "2926  2013-07-03  210.260241               0          0          0          1   \n",
      "2927  2013-07-04  190.686641               0          0          1          0   \n",
      "2928  2013-07-05  181.644870               0          0          1          0   \n",
      "\n",
      "      Temp_Hot  Cloud_Clear  Cloud_Partly_Cloudy  Cloud_Cloudy  ...  Monat_7  \\\n",
      "2924         0            0                    0             1  ...        1   \n",
      "2925         0            0                    1             0  ...        1   \n",
      "2926         0            0                    0             1  ...        1   \n",
      "2927         0            0                    0             1  ...        1   \n",
      "2928         0            0                    1             0  ...        1   \n",
      "\n",
      "      Monat_8  Monat_9  Monat_10  Monat_11  Monat_12  zwischen_den_jahren  \\\n",
      "2924        0        0         0         0         0                    0   \n",
      "2925        0        0         0         0         0                    0   \n",
      "2926        0        0         0         0         0                    0   \n",
      "2927        0        0         0         0         0                    0   \n",
      "2928        0        0         0         0         0                    0   \n",
      "\n",
      "      Number_of_ships_scaled  Cloud_ok  Wind_ok  \n",
      "2924                     0.0         0        1  \n",
      "2925                     0.0         1        1  \n",
      "2926                     0.0         0        1  \n",
      "2927                     0.0         0        1  \n",
      "2928                     0.2         1        1  \n",
      "\n",
      "[5 rows x 57 columns]\n"
     ]
    }
   ],
   "source": [
    "#choose the colums I want to use for the model\n",
    "#kann nun duch einfaches auskommentieren meine gewünschten Splaten ändern\n",
    "colums = ['Datum', \n",
    "        'Umsatz', \n",
    "        'Temp_Very_Cold',\n",
    "        'Temp_Cold', \n",
    "        'Temp_Mild', \n",
    "        'Temp_Warm', \n",
    "        'Temp_Hot', \n",
    "        'Cloud_Clear',\n",
    "       'Cloud_Partly_Cloudy', \n",
    "       'Cloud_Cloudy', \n",
    "       'Wind_Light', \n",
    "       'Wind_Moderate',\n",
    "       'Wind_Strong', \n",
    "       'Weather_Good', \n",
    "       'Weather_Light_Issues',\n",
    "       'Weather_Moderate', \n",
    "       'Weather_Severe', \n",
    "       'KielerWoche', \n",
    "       'Montag',\n",
    "       'Dienstag', \n",
    "       'Mittwoch', \n",
    "       'Donnerstag', \n",
    "       'Freitag', \n",
    "       'Samstag', \n",
    "       'Sonntag',\n",
    "       'VPI',\n",
    "        'Ship', \n",
    "        'Heimspiel', \n",
    "        'Feiertag', \n",
    "        'is_holiday',\n",
    "       'Weihnachtsmarkt', \n",
    "       'Markt', \n",
    "       'Ostertag', \n",
    "       'Silvester',\n",
    "       'wetter_sehr_schön', \n",
    "       'wetter_sehr_schlecht', \n",
    "       'Frühling', \n",
    "       'Sommer',\n",
    "       'Herbst', \n",
    "       'Winter', \n",
    "       'Werktag', \n",
    "       'Monat_1', \n",
    "       'Monat_2', \n",
    "       'Monat_3',\n",
    "       'Monat_4', \n",
    "       'Monat_5', \n",
    "       'Monat_6', \n",
    "       'Monat_7', \n",
    "       'Monat_8', \n",
    "       'Monat_9',\n",
    "       'Monat_10', \n",
    "       'Monat_11', \n",
    "       'Monat_12', \n",
    "       'zwischen_den_jahren',\n",
    "       'Number_of_ships_scaled', \n",
    "       'Cloud_ok', \n",
    "       'Wind_ok']\n",
    "\n",
    "#only use the selceted columns\n",
    "data_train = data_train[colums]\n",
    "data_val = data_val[colums]\n",
    "#in den test daten ist der Umsatz nicht vorhanden, da dieser ja vorhergesagt werden soll\n",
    "colums.remove('Umsatz')\n",
    "data_test = data_test[colums]\n",
    "\n",
    "#einmal die Daten anschauen\n",
    "print(data_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features dimensions: (1462, 55)\n",
      "Validation features dimensions: (357, 55)\n",
      "Test features dimensions: (355, 55)\n",
      "\n",
      "Training labels dimensions: (1462, 1)\n",
      "Validation labels dimensions: (357, 1)\n"
     ]
    }
   ],
   "source": [
    "# Separating features and labels\n",
    "training_features = data_train.drop('Umsatz', axis=1).drop('Datum', axis=1)\n",
    "validation_features = data_val.drop('Umsatz', axis=1).drop('Datum', axis=1)\n",
    "test_features = data_test.drop('Datum', axis=1)\n",
    "\n",
    "training_labels = data_train[['Umsatz']]\n",
    "validation_labels = data_val[['Umsatz']]\n",
    "#test_labels = test_data[['price']]\n",
    "\n",
    "# Print dimensions of the dataframes\n",
    "print(\"Training features dimensions:\", training_features.shape)\n",
    "print(\"Validation features dimensions:\", validation_features.shape)\n",
    "print(\"Test features dimensions:\", test_features.shape)\n",
    "print()\n",
    "print(\"Training labels dimensions:\", training_labels.shape)\n",
    "print(\"Validation labels dimensions:\", validation_labels.shape)\n",
    "#print(\"Test labels dimensions:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subdirectory for the pickle files\n",
    "# Create subdirectory for the pickle files\n",
    "subdirectory = \"pickle_data\"\n",
    "os.makedirs(subdirectory, exist_ok=True)\n",
    "\n",
    "# Export of the prepared data to subdirectory as pickle files\n",
    "training_features.to_pickle(f\"{subdirectory}/training_features.pkl\")\n",
    "validation_features.to_pickle(f\"{subdirectory}/validation_features.pkl\")\n",
    "test_features.to_pickle(f\"{subdirectory}/test_features.pkl\")\n",
    "training_labels.to_pickle(f\"{subdirectory}/training_labels.pkl\")\n",
    "validation_labels.to_pickle(f\"{subdirectory}/validation_labels.pkl\")\n",
    "#test_labels.to_pickle(f\"{subdirectory}/test_labels.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
